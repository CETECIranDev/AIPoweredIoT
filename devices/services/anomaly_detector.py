# ðŸ“ backend/analytics/anomaly_detector.py

import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import datetime
from typing import List, Union

# ------------------- Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ -------------------

class MovingAverageDetector:
    """ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ùˆ Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±"""
    def __init__(self, window: int = 10, threshold: float = 2):
        self.window = window            # ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ùˆ Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±
        self.threshold = threshold      # Ø¶Ø±ÛŒØ¨ Ø­Ø³Ø§Ø³ÛŒØª (Ú†Ù†Ø¯ Ø¨Ø±Ø§Ø¨Ø± Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±)
        self.history = []               # Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

    def detect(self, data: List[float]) -> List[bool]:
        """Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ù„ÛŒØ³ØªÛŒ Ø§Ø² True/False Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯"""
        results = []
        for value in data:
            self.history.append(value)
            if len(self.history) > self.window:
                self.history.pop(0)
            mean = np.mean(self.history)
            std = np.std(self.history)
            results.append(abs(value - mean) > self.threshold * std if std > 0 else False)
        return results


class ZScoreDetector:
    """ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Z-Score"""
    def __init__(self, threshold: float = 2.5):
        self.threshold = threshold      # Ø¶Ø±ÛŒØ¨ Ø­Ø³Ø§Ø³ÛŒØª Z-Score
        self.history = []               # Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

    def detect(self, data: List[float]) -> List[bool]:
        results = []
        for value in data:
            self.history.append(value)
            if len(self.history) < 2:  # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†Ø¨Ø§Ø´Ø¯ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Z-Score Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø±Ø¯
                results.append(False)
                continue
            mean = np.mean(self.history)
            std = np.std(self.history)
            z_score = abs(value - mean) / std if std > 0 else 0
            results.append(z_score > self.threshold)
        return results


class IsolationForestDetector:
    """ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ø¬Ù†Ú¯Ù„ Ø§ÛŒØ²ÙˆÙ„Ù‡ (Isolation Forest)"""
    def __init__(self, contamination: float = 0.15):
        self.model = IsolationForest(contamination=contamination, random_state=42)
        self.is_trained = False         # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡

    def fit(self, X: np.ndarray):
        """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ X"""
        self.model.fit(X)
        self.is_trained = True

    def detect(self, X: np.ndarray) -> List[bool]:
        """ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§"""
        if not self.is_trained:
            self.fit(X)
        predictions = self.model.predict(X)
        return [p == -1 for p in predictions]  # -1 = Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒØŒ 1 = Ù†Ø±Ù…Ø§Ù„


# ------------------- Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Real-Time -------------------

class RealTimeAnomalyDetector:
    """Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Real-Time"""
    def __init__(self):
        self.scaler = StandardScaler()  # Ø¨Ø±Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§
        self.models = {
            'isolation_forest': IsolationForestDetector(contamination=0.15),
            'z_score': ZScoreDetector(threshold=2.5),
            'moving_avg': MovingAverageDetector(window=10, threshold=2)
        }

    # ------------------- Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ -------------------
    def train(self, data: Union[pd.DataFrame, List[float]], column_name: str = "temperature"):
        """
        Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        data: Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ DataFrame ÛŒØ§ Ù„ÛŒØ³Øª Ø³Ø§Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
        column_name: Ù†Ø§Ù… Ø³ØªÙˆÙ†ÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        """
        if isinstance(data, pd.DataFrame):
            if column_name not in data.columns:
                raise ValueError(f"Column {column_name} does not exist")

            values = data[column_name].dropna().values
        else:
            values = np.array(data, dtype=float)

        if len(values) == 0:
            raise ValueError("No data available for training")

        # Ø³Ø§Ø®Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: Ù…Ù‚Ø¯Ø§Ø± ÙØ¹Ù„ÛŒØŒ ØªØ±Ù†Ø¯ØŒ ÙØµÙ„ÛŒ Ø¨ÙˆØ¯Ù†ØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ùˆ Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Û±Û° Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø®ÛŒØ±
        feature_list = []
        for i, val in enumerate(values):
            trend = val - values[i-1] if i > 0 else 0
            seasonality = val - values[i-24] if i >= 24 else 0
            mean = np.mean(values[max(0, i-10):i+1])
            std = np.std(values[max(0, i-10):i+1])
            feature_list.append([val, trend, seasonality, mean, std])

        X = np.array(feature_list)
        X_scaled = self.scaler.fit_transform(X)  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

        # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ joblib
        for name, model in self.models.items():
            if hasattr(model, "fit"):
                model.fit(X_scaled)
                joblib.dump(model, f"{name}_model.pkl")
        print("models trained successfully")

    # ------------------- Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ -------------------
    def predict(self, sensor_data: List[float]) -> List[dict]:
        """
        ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ø³ÙˆØ±
        Ø®Ø±ÙˆØ¬ÛŒ: Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ index, value, anomaly_score, is_anomaly
        """
        results = []

        for i, value in enumerate(sensor_data):
            try:
                value = float(value)
            except:
                value = 0

            trend = value - sensor_data[i-1] if i > 0 else 0
            seasonality = value - sensor_data[i-24] if i >= 24 else 0
            mean = np.mean(sensor_data[max(0, i-10):i+1])
            std = np.std(sensor_data[max(0, i-10):i+1])

            feature_vector = np.array([[value, trend, seasonality, mean, std]])
            X_scaled = self.scaler.transform(feature_vector)

            # Ø±Ø£ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ Ø¨ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ
            anomaly_votes = []
            for model in self.models.values():
                if hasattr(model, "model"):  # IsolationForest
                    pred = model.model.predict(X_scaled)[0]
                    is_anomaly = 1 if pred == -1 else 0
                else:  # Z-Score ÛŒØ§ Moving Average
                    is_anomaly = 1 if model.detect([value])[-1] else 0
                anomaly_votes.append(is_anomaly)

            anomaly_score = np.mean(anomaly_votes)
            is_anomaly = anomaly_score >= 0.34  # Ø­Ø³Ø§Ø³ÛŒØª: 2 Ù…Ø¯Ù„ Ø§Ø² 3 Ø¨Ø§ÛŒØ¯ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ù‡Ù†Ø¯

            results.append({
                'index': i,
                'value': value,
                'anomaly_score': round(anomaly_score, 2),
                'is_anomaly': is_anomaly
            })
        print(results)
        return results
       

    # ------------------- Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ -------------------
    def evaluate(self, y_true: List[int], y_pred: List[int]):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ØªØŒ Ù¾Ø±Ø³ÛŒÚ˜Ù†ØŒ Ø±ÛŒÚ©Ø§Ù„ Ùˆ F1"""
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)
        return {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1": f1
        }


# ------------------- Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª -------------------
if __name__ == "__main__":
    df = pd.read_csv("ml_sensor_data_2000.csv")
    df['date'] = pd.to_datetime(df['timestamp'])
    df.columns = df.columns.str.strip()

    detector = RealTimeAnomalyDetector()
    detector.train(df, column_name="temperature")  # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§

    sensor_data = df['temperature'].tolist()
    anomalies = detector.predict(sensor_data)       # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§

    # ØªØ¨Ø¯ÛŒÙ„ label Ø¨Ù‡ True/False
    y_pred = [a['is_anomaly'] for a in anomalies]
    y_true = df['label'].apply(lambda x: False if str(x).lower() == 'normal' else True).tolist()

    metrics = detector.evaluate(y_true, y_pred)
    print(f"Accuracy:  {metrics['accuracy']*100:.2f}%")
    print(f" Precision: {metrics['precision']*100:.2f}%")
    print(f" Recall:    {metrics['recall']*100:.2f}%")
  
